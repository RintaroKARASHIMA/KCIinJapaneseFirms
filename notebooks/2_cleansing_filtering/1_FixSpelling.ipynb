{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "import regex\n",
    "\n",
    "import datetime\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global data_dir, ex_data_dir, output_dir\n",
    "data_dir = '../../data/interim/internal/merged/'\n",
    "ex_data_dir = '../../data/processed/external/'\n",
    "output_dir = '../../data/interim/internal/fixed/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sorted(glob(data_dir + '*.csv'))[-1], \n",
    "                 sep=',', \n",
    "                 encoding='utf-8', \n",
    "                 dtype=str)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_kanjikana_df = pd.read_csv(f'{ex_data_dir}letter/kanjikana.csv',\n",
    "                                 sep=',',\n",
    "                                 encoding='utf-8', \n",
    "                                 dtype=str)\n",
    "company_master_df = pd.read_csv(f'{ex_data_dir}nistep/company_master.csv', \n",
    "                                sep=',', \n",
    "                                encoding='utf-8', \n",
    "                                dtype=str)\n",
    "company_master_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_kanjikana_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験場\n",
    "# list(df[df['right_person_name'].str.contains('\\?ｫ|▲', regex=True)]\\\n",
    "#         [['right_person_name']]\\\n",
    "#         .drop_duplicates(subset=['right_person_name'], keep='first')\\\n",
    "#         .sort_values('right_person_name', ascending=True)['right_person_name'].unique())#.head(30)\n",
    "# adate_df[adate_df['right_person_name'].str.contains('キヤノン')]['right_person_name'].unique()\n",
    "# df[df['right_person_name'].str.startswith('愛知県')]['right_person_name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('表記ゆれ処理前の特許権者数：', df['right_person_name'].nunique())\n",
    "print('表記ゆれ処理前の特許数：', df['reg_num'].nunique())\n",
    "print('表記ゆれ処理前のIPC数：', df['ipc'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字化けシリーズ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_specialstr_tuple = (\n",
    "    ('?b', '高'), \n",
    "    ('?C', '吉'), \n",
    "    ('?D', '塚'), \n",
    "    ('?F', '崎'), \n",
    "    ('?H', '徳'), \n",
    "    ('?P', '濾'), \n",
    "    ('?芟ｴ', '桑原'), \n",
    "    ('??', '')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trans_specialstr in trans_specialstr_tuple:\n",
    "    df['right_person_name'] = df['right_person_name'].str.replace(trans_specialstr[0], trans_specialstr[1], regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # デバッグ用コード\n",
    "# list(df[df['right_person_name'].str.contains('??', regex=False)]['right_person_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一文字の違いシリーズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一文字から一文字への変換辞書\n",
    "trans_one_letter_dict = dict(zip(trans_kanjikana_df['old_jikei'].values, \n",
    "                               trans_kanjikana_df['new_jikei'].values))\n",
    "\n",
    "# 消す文字のリスト\n",
    "trans_noise_list = ['\\u3000', '\\?ｫ', '\\?ｬ', '▲', '▼', ' ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旧字体を新字体に変換，消す文字を消す\n",
    "for col_name in ['right_person_addr', 'right_person_name']:\n",
    "    df[col_name] = df[col_name].str.replace('|'.join(trans_noise_list), '', regex=True)\\\n",
    "                                                 .str.translate(str.maketrans(trans_one_letter_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in ['before_name', 'after_name']:\n",
    "    company_master_df[col_name] = company_master_df[col_name].str.replace('|'.join(trans_noise_list), '', regex=True)\\\n",
    "                                                             .str.translate(str.maketrans(trans_one_letter_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 省庁とか\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 省庁合併のタプルを作る用のデータ\n",
    "minis_office_df = pd.read_csv(f'{ex_data_dir}ministry/minis_office.csv', \n",
    "                              encoding='utf-8', sep=',', dtype=object)\n",
    "minis_office_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大臣とかの修正\n",
    "trans_minister_tuple = tuple([('大臣', '省')])\\\n",
    "                       +tuple(zip(minis_office_df['old_office'].values, minis_office_df['after_office'].values))\n",
    "# trans_minister_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_list = []\n",
    "i = 0\n",
    "for trans_minister in trans_minister_tuple:\n",
    "    if i in [0, 31, 37, 47, 51, 52, 56, 61, 63, 73, 74, 88, 89, 91, 92, 93, 94, 96, 97, 98, 100, 102, 104, 109, 110, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123]:\n",
    "        exception_list.append(df[df['right_person_name'].str.contains(trans_minister[0])]['right_person_name'].str.replace(trans_minister[0], '').unique())\n",
    "        df['right_person_name'] = df['right_person_name'].str.replace(trans_minister[0], trans_minister[1], regex=True)\n",
    "    i += 1\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 官庁とか何かの長とか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何らかの長の表記ゆれ\n",
    "trans_top_tuple = (\n",
    "               ('総長|長官', ''), \n",
    "               ('所長', '所'), \n",
    "               ('局長', '局'), \n",
    "               ('院長', '院'), \n",
    "               ('大学{1,2}長', '大学'), \n",
    "               ('校長', '校'), \n",
    "               ('課長', '課'), \n",
    "               ('部長', '部'), \n",
    "               ('センター長', 'センター'), \n",
    "               ('機構長', '機構'), \n",
    "               ('署長', '署'), \n",
    "               ('場長', '場'), \n",
    "               ('市長', '市')\n",
    "               )\n",
    "\n",
    "# 企業名の表記ゆれ\n",
    "trans_lp_tuple = (('コーポレイシヨン', 'コーポレーシヨン'), \n",
    "                  ('株式会社', '株式'), \n",
    "                  ('株式', '株式会社'))\n",
    "\n",
    "trans_else_tuple = (\n",
    "               ('パナソニツクＩＰマネジメント株式会社', 'パナソニツク株式会社'), \n",
    "               ('ッ', 'ツ')\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trans_top in trans_top_tuple+trans_lp_tuple:\n",
    "    df['right_person_name'] = df['right_person_name'].str.replace(trans_top[0], trans_top[1], regex=True)\n",
    "    for col_name in ['before_name', 'after_name']:\n",
    "        company_master_df[col_name] = company_master_df[col_name].str.replace(trans_top[0], trans_top[1], regex=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 合併\n",
    "df = pd.merge(df, company_master_df.rename(columns={'before_name':'right_person_name'}), \n",
    "              on='right_person_name', \n",
    "              how='left')\\\n",
    "             .rename(columns={'after_name':'after_right_person_name'})\n",
    "df['after_right_person_name'] = df['after_right_person_name'].fillna(df['right_person_name'])\n",
    "df = df.drop(columns=['right_person_name'])\\\n",
    "       .rename(columns={'after_right_person_name':'right_person_name'})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../Data/Tmp/fixed.csv', encoding='utf-8', sep=',', index=False)\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "now = datetime.datetime.now(jst)\n",
    "str_now = now.strftime('%Y%m')\n",
    "\n",
    "df.to_csv(f'{output_dir}{str_now}.csv', \n",
    "          sep=',', \n",
    "          encoding='utf-8', \n",
    "          index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
