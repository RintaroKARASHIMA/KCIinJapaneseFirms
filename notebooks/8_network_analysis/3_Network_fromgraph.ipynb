{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=top></a>\n",
    "\n",
    "# **目次**\n",
    "\n",
    "<b>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=#modules, style=\"font-size: xx-large\">1. モジュールインポート</a>\n",
    "            <ul>※サードパーティライブラリ>>>自作モジュール>>>（ここまで本ipynb外）>>>自作関数（本ipynb内）</ul>\n",
    "        </summary>\n",
    "    </details>\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <a href=#data , style=\"font-size: xx-large\">2. オリジナルデータインポート</a>\n",
    "    </summary>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <a href=\"#all\", style=\"font-size: xx-large\">3. 全体</a>\n",
    "    </summary>\n",
    "    <table></table>\n",
    "</details>\n",
    "    \n",
    "<details>\n",
    "    <summary>\n",
    "        <a href=\"#sepyear\", style=\"font-size: xx-large\">4. 期間ごと</a>\n",
    "    </summary>\n",
    "</details>\n",
    "</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=modules></a>\n",
    "\n",
    "## **1. モジュールインポート**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src\")\n",
    "from ecomplexity import ecomplexity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "import matplotlib.ticker as ptick\n",
    "import networkx as nx\n",
    "import networkx.algorithms.bipartite as bip\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Meiryo\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "# 小数点以下 桁数 6\n",
    "pd.options.display.float_format = \"{:.3f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自作モジュールインポート\n",
    "import initial_condition\n",
    "from process import weight\n",
    "from visualize import rank as vr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccdf(diversity_col: list):\n",
    "        freq_array = np.array(np.bincount(diversity_col))\n",
    "        p_list = []\n",
    "        cumsum = 0.0\n",
    "        s = float(freq_array.sum())\n",
    "        for freq in freq_array:\n",
    "            if freq != 0:\n",
    "                cumsum += freq / s\n",
    "                p_list.append(cumsum)\n",
    "            else:\n",
    "                p_list.append(1.0)\n",
    "                \n",
    "        ccdf_array = 1 - np.array(p_list)\n",
    "        if ccdf_array[0] == 0:\n",
    "            ccdf_array[0] = 1.0\n",
    "        return ccdf_array\n",
    "\n",
    "color_list = ['red']+[\n",
    "    'red', 'green', 'blue', 'yellow', 'orange', 'purple', 'pink', 'brown',\n",
    "    'grey', 'violet', 'indigo', 'turquoise', 'gold', 'lime', 'coral',\n",
    "    'navy', 'skyblue', 'tomato', 'olive', 'cyan', 'darkred', 'darkgreen',\n",
    "    'darkblue', 'darkorange', 'darkviolet', 'deeppink', 'firebrick', 'darkcyan',\n",
    "    'darkturquoise', 'darkslategray', 'darkgoldenrod', 'mediumblue', 'mediumseagreen',\n",
    "    'mediumpurple', 'mediumvioletred', 'midnightblue', 'saddlebrown', 'seagreen',\n",
    "    'sienna', 'steelblue'\n",
    "    ][10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccdf(target_array:np.array):\n",
    "    freq_array = np.array(np.bincount(target_array))\n",
    "    p_list = []\n",
    "    cumsum = 0.0\n",
    "    s = float(freq_array.sum())\n",
    "    for freq in freq_array:\n",
    "        if freq != 0:\n",
    "            cumsum +=freq / s\n",
    "            p_list.apend(cumsum)\n",
    "        else:\n",
    "            p_list.append(1.0)\n",
    "    ccdf_array = 1 - np.arrau(p_list)\n",
    "    if ccdf_array[0] == 0: ccdf_array[0] = 1.0\n",
    "    return ccdf_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def descript_network(graph_df:pd.DataFrame, \n",
    "                     hr_col:str='right_person_name', \n",
    "                     class_col:str='ipc_class', \n",
    "                     segment_col:str='1981-2010'\n",
    "                     ):\n",
    "    # ネットワークの特性を調べる\n",
    "    BG = nx.Graph()\n",
    "    BG.add_nodes_from(graph_df[hr_col].unique(), bipartite=0)\n",
    "    BG.add_nodes_from(graph_df[class_col].unique(), bipartite=1)\n",
    "    BG.add_edges_from(list(zip(graph_df[hr_col], graph_df[class_col])))\n",
    "    \n",
    "    if nx.is_connected(BG): print('連結性ある')\n",
    "    else: print('連結性ない')\n",
    "    \n",
    "    # 特許権者ノード\n",
    "    hr_nodes = {n for n, d in BG.nodes(data=True) if d['bipartite'] == 0}\n",
    "    hr_degree_array = ccdf(dict(bip.degrees(BG, hr_nodes)[1]).values())\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 特許分類ノード\n",
    "    ipc_nodes = set(BG) - hr_nodes\n",
    "    ipc_degree_array = ccdf(dict(bip.degrees(BG, ipc_nodes)[1]).values())\n",
    "    \n",
    "    # G = nx.from_pandas_edgelist(graph_df, 'source', 'target', edge_attr=True)\n",
    "    # print(nx.info(G))\n",
    "    # print('平均最短距離:', nx.average_shortest_path_length(G))\n",
    "    # print('平均クラスタリング係数:', nx.average_clustering(G))\n",
    "    # print('直径:', nx.diameter(G))\n",
    "    # print('半径:', nx.radius(G))\n",
    "    # print('次数中心性:', nx.degree_centrality(G))\n",
    "    # print('媒介中心性:', nx.betweenness_centrality(G))\n",
    "    # print('固有ベクトル中心性:', nx.eigenvector_centrality(G))\n",
    "    # print('PageRank:', nx.pagerank(G))\n",
    "    # print('次数分布:', nx.degree_histogram(G))\n",
    "    res_dict = {\n",
    "                'network':BG}\n",
    "    \n",
    "    return BG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global data_dir, ex_dir, output_dir\n",
    "data_dir = \"../../data/processed/internal/graph/\"\n",
    "ex_dir = \"../../data/processed/external/\"\n",
    "output_dir = \"../../output/figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期条件\n",
    "ar = initial_condition.AR\n",
    "year_style = initial_condition.YEAR_STYLE\n",
    "\n",
    "year_start = initial_condition.YEAR_START\n",
    "year_end = initial_condition.YEAR_END\n",
    "year_range = initial_condition.YEAR_RANGE\n",
    "\n",
    "extract_population = initial_condition.EXTRACT_POPULATION\n",
    "top_p_or_num = initial_condition.TOP_P_OR_NUM\n",
    "region_corporation = initial_condition.REGION_CORPORATION\n",
    "applicant_weight = initial_condition.APPLICANT_WEIGHT\n",
    "\n",
    "classification = initial_condition.CLASSIFICATION\n",
    "class_weight = initial_condition.CLASS_WEIGHT\n",
    "\n",
    "color_list = initial_condition.COLOR_LIST\n",
    "\n",
    "input_condition = f'{ar}_{year_style}_{extract_population}_{top_p_or_num[0]}_{top_p_or_num[1]}_{region_corporation}_{applicant_weight}_{classification}_{class_weight}'\n",
    "fig_name_base = f'{ar}_{year_style}_{extract_population}_{top_p_or_num[0]}_{top_p_or_num[1]}_{region_corporation}_{applicant_weight}_{classification}_{class_weight}.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = pd.read_csv(data_dir + f'{input_condition}_edge.csv', \n",
    "                       encoding='utf-8', \n",
    "                       sep=','\n",
    "                       )\n",
    "node_df = pd.read_csv(data_dir + f'{input_condition}_node.csv', \n",
    "                       encoding='utf-8', \n",
    "                       sep=','\n",
    "                       )\n",
    "# edge_df\n",
    "# graph_dict = {}\n",
    "# for s in graph_df['segment'].unique():\n",
    "       \n",
    "#        graph_df = graph_df[graph_df['segment'] == '1981-2010']\n",
    "# graph_df.groupby('right_person_name')[['mcp']].sum().sort_values('mcp', ascending=False).head(10)\n",
    "graph_df = pd.merge(edge_df, node_df, left_on='Source', right_on='node_id', how='left')\\\n",
    "                   [['Target', 'label']]\\\n",
    "                   .rename(columns={'label':region_corporation})\n",
    "graph_df = pd.merge(graph_df, node_df, left_on='Target', right_on='node_id', how='left')\\\n",
    "                     [['label', region_corporation]]\\\n",
    "                        .rename(columns={'label':classification})\n",
    "graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG = nx.Graph()\n",
    "BG.add_nodes_from(graph_df[region_corporation].unique(), bipartite=0)\n",
    "BG.add_nodes_from(graph_df[classification].unique(), bipartite=1)\n",
    "BG.add_edges_from(list(zip(graph_df[region_corporation], graph_df[classification])))\n",
    "\n",
    "if nx.is_connected(BG): print('連結性ある')\n",
    "else: print('連結性ない')\n",
    "\n",
    "# 特許権者ノード\n",
    "hr_nodes = {n for n, d in BG.nodes(data=True) if d['bipartite'] == 0}\n",
    "# hr_degree_array = ccdf(dict(bip.degrees(BG, hr_nodes)[1]).values())\n",
    "hr_nodes\n",
    "\n",
    "\n",
    "# 特許分類ノード\n",
    "ipc_nodes = set(BG) - hr_nodes\n",
    "ipc_nodes\n",
    "# ipc_degree_array = ccdf(dict(bip.degrees(BG, ipc_nodes)[1]).values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>先頭に戻る</a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=#description></a>\n",
    "\n",
    "## **1. 記述統計**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特許権者ノード\n",
    "hr_nodes = {n for n, d in BG.nodes(data=True) if d['bipartite'] == 0}\n",
    "\n",
    "# 特許分類ノード\n",
    "ipc_nodes = set(BG) - hr_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特許権者ノードの密度\n",
    "print(round(bip.density(BG, hr_nodes), 3))\n",
    "\n",
    "# 特許分類ノードの密度\n",
    "print(round(bip.density(BG, ipc_nodes), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_count = 0\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "for s in list(right_person_df['segment'].unique())[0:1]:\n",
    "    ccdf_array = ccdf(right_person_df[right_person_df['segment']==s]['diversity'].to_list())\n",
    "    ax.plot(range(1, len(ccdf_array)+1), ccdf_array, 'o', markersize=7, \n",
    "                    color=color_list[color_count], label=s+'年度', alpha=0.6)\n",
    "    color_count += 1\n",
    "    print(right_person_df[right_person_df['segment']==s]['diversity'].mean())\n",
    "    print(right_person_df[right_person_df['segment']==s]['right_person_name'].nunique())\n",
    "    print(right_person_df[right_person_df['segment']==s]['diversity'].mean() * right_person_df[right_person_df['segment']==s]['right_person_name'].nunique())\n",
    "    # print(right_person_df[right_person_df['segment']==s]['diversity'].mean() * right_person_df[right_person_df['segment']==s]['right_person_name'].nunique()/627)\n",
    "    # print(right_person_df[right_person_df['segment']==s]['diversity'].mean())\n",
    "ax.legend(loc='lower left', fontsize=18)\n",
    "# ax.legend(loc='upper right', fontsize=18)\n",
    "\n",
    "# ax.set_title('各期間における特許権者の補累積次数（Diversity）分布（両対数スケール）'+'\\n', fontsize=20)\n",
    "ax.set_xlabel('特許権者次数（Diversity）', fontsize=18)\n",
    "ax.set_ylabel('ccdf', fontsize=18)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.set_xlim(0.8, 300)\n",
    "\n",
    "# x軸の指数表記を普通に戻す魔法\n",
    "ax.xaxis.set_major_formatter(ptick.ScalarFormatter(useMathText=True))\n",
    "\n",
    "# ax.set_xlim(prop_dict['xlim'])\n",
    "# ax.set_ylim(prop_dict['ylim'])\n",
    "\n",
    "ax.grid(axis='both', \n",
    "        which='major', \n",
    "        alpha=1, \n",
    "        linestyle='--', \n",
    "        linewidth=0.6, \n",
    "        color='gray')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特許権者同士のつながり\n",
    "hr_G = bip.projected_graph(BG, hr_nodes)\n",
    "hr_degree_dict = dict(hr_G.degree())\n",
    "\n",
    "print(max(hr_degree_dict, key=hr_degree_dict.get))\n",
    "# hr_degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特許分類同士のつながり\n",
    "ipc_G = bip.weighted_projected_graph(BG, ipc_nodes)\n",
    "ipc_degree_dict = dict(ipc_G.degree())\n",
    "for n, w in dict(bip.degrees(BG, ipc_nodes)[1]).items():\n",
    "    ipc_G.nodes[n]['weight'] = w\n",
    "print(max(ipc_degree_dict, key=ipc_degree_dict.get))\n",
    "# ipc_degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_G.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ipc_G.nodes[node]['weight'] for node in ipc_G.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bip.degrees(BG, hr_nodes)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_array = nx.to_numpy_array(BG)[:1938, 1938:]\n",
    "diversity_array = adj_array.sum(axis=1)\n",
    "ubiquity_array = adj_array.sum(axis=0)\n",
    "M_ff = ((adj_array * adj_array) / np.outer(diversity_array, ubiquity_array)).sum(axis=0)\n",
    "np.linalg.eigh(M_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隣接行列の取得\n",
    "A = nx.to_numpy_array(ipc_G, weight='weight')\n",
    "node_weights_array = np.array([ipc_G.nodes[node]['weight'] for node in ipc_G.nodes()])\n",
    "W = np.diag(node_weights_array)\n",
    "\n",
    "# ラプラシアン行列の計算\n",
    "D = np.diag(np.sum(A, axis=1))\n",
    "L = D - A\n",
    "# L_gen = W @ L @ W\n",
    "L_gen = L\n",
    "\n",
    "# 固有値と固有ベクトルの計算\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(L_gen)\n",
    "\n",
    "# 2番目に大きい固有値に対応する固有ベクトルの取得\n",
    "second_largest_index = np.argsort(eigenvalues)[-1]\n",
    "second_largest_eigenvector = eigenvectors[:, second_largest_index]\n",
    "print(\"2番目に大きい固有値に対応する固有ベクトル:\", second_largest_eigenvector)\n",
    "\n",
    "TCI = (second_largest_eigenvector - np.mean(second_largest_eigenvector))/np.std(second_largest_eigenvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ev in enumerate(eigenvalues):\n",
    "    if ev == sorted(eigenvalues)[1]:\n",
    "        print(i, ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCI = (eigenvectors[1] - np.mean(eigenvectors[1]))/eigenvectors[1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TCI_dict = {}\n",
    "for i, f, in enumerate(list(ipc_G.nodes())):\n",
    "    # print(f, TCI[i])\n",
    "    TCI_dict[f] = TCI[i]\n",
    "print(max(TCI_dict, key=TCI_dict.get))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "economic_complexity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
