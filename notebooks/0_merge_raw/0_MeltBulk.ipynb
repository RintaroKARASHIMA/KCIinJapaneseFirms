{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=top></a>\n",
    "\n",
    "# **目次**\n",
    "\n",
    "<b>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#modules\", style=\"font-size: xx-large\">1. モジュールインポート</a>\n",
    "            <ul>※サードパーティライブラリ>>>自作モジュール>>>（ここまで本ipynb外）>>>自作関数（本ipynb内）</ul>\n",
    "        </summary>\n",
    "    </details>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#getdata\", style=\"font-size: xx-large\">2. データのゲット</a>\n",
    "        </summary>\n",
    "    </details>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#melttargz\", style=\"font-size: xx-large\">3. targz展開</a>\n",
    "        </summary>\n",
    "        <table></table>\n",
    "    </details>\n",
    "</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=modules></a>\n",
    "\n",
    "## **1. モジュールインポート**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global data_dir, excute_count\n",
    "data_dir = '../../data/original/internal/'\n",
    "excute_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得\n",
    "def get_data(master_name, coding='utf-8'):\n",
    "    html_file = f'{data_dir}bulk_html/{master_name}.html'\n",
    "    output_dir = f'{data_dir}bulk_targz/{master_name}/'\n",
    "    \n",
    "    with open(html_file, 'r', encoding=coding) as f:\n",
    "        html_text = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    href_list = list(set(href for href in [a.get('href') for a in soup.select('div a')]\\\n",
    "                                          if master_name in href))\n",
    "    for href in href_list:\n",
    "        urllib.request.urlretrieve(href, filename=output_dir+href.split('/')[-1])\n",
    "        # print(f'Downloaded: {href.split(\"/\")[-1]}')\n",
    "        time.sleep(3)\n",
    "    print(master_name, 'got!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ解凍\n",
    "def extract_data(master_name):\n",
    "    needed_file_dict = {\n",
    "                        'JPWRP': [# 登録マスタ\n",
    "                                  'upd_mgt_info_p.tsv', \n",
    "                                  'upd_right_person_art_p.tsv', \n",
    "                                 ], \n",
    "                        'JPWIP': [# IPCマスタ\n",
    "                                 'upd_dsptch_fin_ipc.tsv', \n",
    "                                 ], \n",
    "                        'JPWAP': [# 出願マスタ\n",
    "                                 'upd_pmac_g_app_case.tsv', \n",
    "                                 'upd_sinseinin.tsv'\n",
    "                                 ]\n",
    "                        }\n",
    "    targz_list = glob(f'{data_dir}bulk_targz/{master_name}/*')\n",
    "    for targz in targz_list:\n",
    "        with tarfile.open(name=targz, mode='r:gz') as tf:\n",
    "            member_list = tf.getmembers()\n",
    "            file_date = targz.split(f'{master_name}_')[-1].split('.')[0]\n",
    "            \n",
    "            for member in member_list:\n",
    "                file_name = member.name.split('/')[-1]\n",
    "                if file_name in needed_file_dict[master_name]:\n",
    "                    needed_dir = file_name.split('.')[0]\n",
    "                    member.name = f'{data_dir}bulk/{master_name}/{needed_dir}/{file_date}.tsv'\n",
    "                    \n",
    "                    # 誰に何と言われようと、バージョンに依存するメソッドは嫌いです。\n",
    "                    tf.extract(member, path='.')\n",
    "                    # print(f'Extracted: {folder_name}/{file_name}')\n",
    "            tf.close()\n",
    "    print(master_name, 'melted!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mn in ['JPWRP', 'JPWIP', 'JPWAP']:\n",
    "    # if excute_count == 0: get_data(mn)\n",
    "    excute_count += 1\n",
    "    extract_data(mn)\n",
    "print('completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
