{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=top></a>\n",
    "\n",
    "# **目次**\n",
    "\n",
    "<b>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#modules\", style=\"font-size: xx-large\">1. モジュールインポート</a>\n",
    "            <ul>※サードパーティライブラリ>>>自作モジュール>>>（ここまで本ipynb外）>>>自作関数（本ipynb内）</ul>\n",
    "        </summary>\n",
    "    </details>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#data\", style=\"font-size: xx-large\">2. オリジナルデータインポート</a>\n",
    "        </summary>\n",
    "    </details>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#patentcount\", style=\"font-size: xx-large\">3. 特許数</a>\n",
    "        </summary>\n",
    "        <table></table>\n",
    "    </details>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#calculateindicator\", style=\"font-size: xx-large\">4. 各指標</a>\n",
    "        </summary>\n",
    "    </details>\n",
    "    <details>\n",
    "        <summary>\n",
    "            <a href=\"#output\", style=\"font-size: xx-large\">5. ファイルに出力</a>\n",
    "        </summary>\n",
    "    </details>\n",
    "</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=modules></a>\n",
    "\n",
    "## **1. モジュールインポート**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "from ecomplexity import ecomplexity\n",
    "\n",
    "# 小数点以下 桁数 6\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import initial_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global data_dir, output_dir\n",
    "data_dir = '../../data/interim/internal/filtered_after_agg/'\n",
    "output_dir = '../../data/processed/internal/'\n",
    "ex_dir = '../../data/processed/external/schmoch/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期条件\n",
    "ar = initial_condition.AR\n",
    "year_style = initial_condition.YEAR_STYLE\n",
    "\n",
    "year_start = initial_condition.YEAR_START\n",
    "year_end = initial_condition.YEAR_END\n",
    "year_range = initial_condition.YEAR_RANGE\n",
    "\n",
    "extract_population = initial_condition.EXTRACT_POPULATION\n",
    "top_p_or_num = initial_condition.TOP_P_OR_NUM\n",
    "# top_p_or_num = ('p', 100)\n",
    "region_corporation = initial_condition.REGION_CORPORATION\n",
    "# region_corporation = 'right_person_addr'\n",
    "applicant_weight = initial_condition.APPLICANT_WEIGHT\n",
    "\n",
    "classification = initial_condition.CLASSIFICATION\n",
    "class_weight = initial_condition.CLASS_WEIGHT\n",
    "\n",
    "input_condition = f'{ar}_{year_style}_{extract_population}_{top_p_or_num[0]}_{top_p_or_num[1]}_{region_corporation}_{applicant_weight}_{classification}_{class_weight}'\n",
    "output_condition = f'{ar}_{year_style}_{extract_population}_{top_p_or_num[0]}_{top_p_or_num[1]}_{region_corporation}_{applicant_weight}_{classification}_{class_weight}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kh_ki(c_df, classification, n=19):\n",
    "    kh1_ki1_df = pd.merge(c_df.copy(), \n",
    "                        c_df[c_df['mcp']==1].groupby([region_corporation])[['ubiquity']].sum().reset_index(drop=False).copy().rename(columns={'ubiquity':'kh_1'}), \n",
    "                        on=[region_corporation], how='left')\n",
    "    kh1_ki1_df = pd.merge(kh1_ki1_df.copy(), \n",
    "                        c_df[c_df['mcp']==1].groupby([classification])[['diversity']].sum().reset_index(drop=False).copy().rename(columns={'diversity':'ki_1'}), \n",
    "                        on=[classification], how='left')\n",
    "    kh1_ki1_df['kh_1'] = kh1_ki1_df['kh_1'] / kh1_ki1_df['diversity']\n",
    "    kh1_ki1_df['ki_1'] = kh1_ki1_df['ki_1'] / kh1_ki1_df['ubiquity']\n",
    "    kh_ki_df = kh1_ki1_df.copy()\n",
    "    for i in range(n):\n",
    "        kh_ki_df = pd.merge(kh_ki_df, \n",
    "                            kh_ki_df[kh_ki_df['mcp']==1].groupby([region_corporation])[[f'ki_{i+1}']].sum().reset_index(drop=False).copy()\\\n",
    "                                        .rename(columns={f'ki_{i+1}':f'kh_{i+2}'}), \n",
    "                            on=[region_corporation], how='left')\n",
    "        kh_ki_df = pd.merge(kh_ki_df, \n",
    "                            kh_ki_df[kh_ki_df['mcp']==1].groupby([classification])[[f'kh_{i+1}']].sum().reset_index(drop=False).copy()\\\n",
    "                                        .rename(columns={f'kh_{i+1}':f'ki_{i+2}'}), \n",
    "                            on=[classification], how='left')\n",
    "        kh_ki_df[f'kh_{i+2}'] = kh_ki_df[f'kh_{i+2}'] / kh_ki_df['diversity']\n",
    "        kh_ki_df[f'ki_{i+2}'] = kh_ki_df[f'ki_{i+2}'] / kh_ki_df['ubiquity']\n",
    "    return kh_ki_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=data></a>\n",
    "\n",
    "## **2. オリジナルデータインポート**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schmoch_df = pd.read_csv(f'{ex_dir}35.csv', \n",
    "                         encoding='utf-8', \n",
    "                         sep=',', \n",
    "                         usecols=['Field_number', 'Field_en']\n",
    "                         ).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_num_top_df = pd.read_csv(f'{data_dir}{input_condition}.csv', \n",
    "                             encoding='utf-8',\n",
    "                             sep=',')\n",
    "reg_num_top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_num_top_df[region_corporation].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>先頭に戻る</a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=calculateindicator></a>\n",
    "\n",
    "## **4. 各指標**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_cols = {'time':f'{ar}_{year_style}_period', 'loc':region_corporation, 'prod':classification, 'val':'reg_num'}\n",
    "rename_col_dict = {'eci':'kci', 'pci':'tci'}\n",
    "col_order_list = [f'{ar}_{year_style}_period', region_corporation, classification, 'reg_num', 'rca', 'mcp', 'diversity', 'ubiquity', 'kci', 'tci']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = ecomplexity(reg_num_top_df,\n",
    "                   cols_input = trade_cols, \n",
    "                   rca_mcp_threshold = 1)\n",
    "# c_out_df = c_df.copy()\n",
    "c_df = c_df[c_df['reg_num'] > 0]\\\n",
    "           .rename(columns=rename_col_dict)\\\n",
    "           [col_order_list]\n",
    "c_df = pd.concat([kh_ki(c_df[c_df[f'{ar}_{year_style}_period'] == period], classification) for period in c_df[f'{ar}_{year_style}_period'].unique()], \n",
    "                 axis='index', \n",
    "                 ignore_index=True)\n",
    "\n",
    "# for segment in c_df[f'{ar}_{year_style}_period'].unique():\n",
    "#     display(c_df[c_df[f'{ar}_{year_style}_period'] == segment].head())\n",
    "#     display(c_df[c_df[f'{ar}_{year_style}_period'] == segment].describe())\n",
    "#     print(c_df[c_df[f'{ar}_{year_style}_period'] == segment].info())\n",
    "#     print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df.sort_values(by=[f'{ar}_{year_style}_period', 'kci'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df[(c_df[classification]==22)&(c_df[f'{ar}_{year_style}_period']=='1981-1990')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">先頭に戻る</a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=output></a>\n",
    "\n",
    "## **5. ファイルに出力**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=rightperson></a>\n",
    "\n",
    "### **5.1. 特許権者**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "right_person_df = pd.merge(c_df.groupby([f'{ar}_{year_style}_period', region_corporation])[['reg_num']].sum().reset_index(drop=False), \n",
    "                           c_df.groupby([f'{ar}_{year_style}_period', region_corporation])[[classification]].nunique().reset_index(drop=False), \n",
    "                           on=[f'{ar}_{year_style}_period', region_corporation], \n",
    "                           how='inner')\n",
    "right_person_df = pd.merge(right_person_df, \n",
    "                           c_df[[f'{ar}_{year_style}_period', region_corporation, 'diversity', 'kci']\\\n",
    "                               +[f'kh_{i}' for i in range(1, 20+1)]]\\\n",
    "                               .drop_duplicates(keep='first'), \n",
    "                           on=[f'{ar}_{year_style}_period', region_corporation], \n",
    "                           how='inner')\n",
    "# for period in right_person_df[f'{ar}_{year_style}_period'].unique():\n",
    "#     right_person_df\n",
    "\n",
    "# for period in right_person_df[f'{ar}_{year_style}_period'].unique():\n",
    "#     for i in range(1, 20+1):\n",
    "#         value = right_person_df[right_person_df[f'{ar}_{year_style}_period']==period]\n",
    "#         right_person_df[right_person_df[f'{ar}_{year_style}_period']==period][f'kh_{i}'] = (value[f'kh_{i}'] - value[f'kh_{i}'].mean()) / value[f'kh_{i}'].std()\n",
    "#     display(right_person_df[right_person_df[f'{ar}_{year_style}_period'] == period].head())\n",
    "#     display(right_person_df[right_person_df[f'{ar}_{year_style}_period'] == period].describe())\n",
    "#     print(right_person_df[right_person_df[f'{ar}_{year_style}_period'] == period].info())\n",
    "#     print('\\n')\n",
    "# right_person_df['reg_num'] = right_person_df['reg_num'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schmoch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.merge(c_df, schmoch_df, \n",
    "         left_on=classification, right_on='Field_number', how='left')\n",
    "sample[(sample[f'{ar}_{year_style}_period']==f'{year_start}-{year_end}')&(sample['Field_en']=='Digital communication')&\\\n",
    "    (sample['mcp']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_person_df[right_person_df[f'{ar}_{year_style}_period']==f'{year_start}-{year_end}'].sort_values('kci', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_person_df.to_csv(f'{output_dir}firms/{output_condition}.csv', \n",
    "                       encoding='utf-8', \n",
    "                       sep=',', \n",
    "                       index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_person_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>先頭に戻る</a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ipc></a>\n",
    "\n",
    "### **5.2. IPC**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schmoch_df = pd.read_csv(f'{ex_dir}35.csv', \n",
    "                         encoding='utf-8', \n",
    "                         sep=',', \n",
    "                         usecols=['Field_number', 'Field_en']\n",
    "                         ).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各期間\n",
    "classification_df = pd.merge(c_df.groupby([f'{ar}_{year_style}_period', classification])[['reg_num']].sum().reset_index(drop=False), \n",
    "                        c_df.groupby([f'{ar}_{year_style}_period', classification])[[region_corporation]].nunique().reset_index(drop=False), \n",
    "                        on=[f'{ar}_{year_style}_period', classification], \n",
    "                        how='inner')\n",
    "classification_df = pd.merge(classification_df, \n",
    "                      c_df[[f'{ar}_{year_style}_period', classification, 'ubiquity', 'tci']\\\n",
    "                          +[f'ki_{i}' for i in range(1, 20+1)]]\\\n",
    "                          .drop_duplicates(keep='first'), \n",
    "                      on=[f'{ar}_{year_style}_period', classification], \n",
    "                      how='inner')\n",
    "# classification_df['reg_num'] = classification_df['reg_num'].astype(np.int64)\n",
    "classification_df = pd.merge(classification_df, \n",
    "                            schmoch_df.rename(columns={'Field_number':classification}), \n",
    "                            on=[classification], \n",
    "                            how='inner')\\\n",
    "                            .drop(columns=[classification])\\\n",
    "                            .rename(columns={'Field_en':classification})\n",
    "display(classification_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df.to_csv(f'{output_dir}technology/{output_condition}.csv', \n",
    "                        encoding='utf-8', \n",
    "                        sep=',', \n",
    "                        index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>先頭に戻る</a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=network></a>\n",
    "\n",
    "## **5.3. 二部グラフ用**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eneos_df = c_df[(c_df[f'{ar}_{year_style}_period']==f'{year_start}-{year_end}')&(c_df[region_corporation].str.contains('ＥＮＥＯＳ'))\\\n",
    "#                 &(c_df['mcp']==1)].copy()#[[region_corporation, 'reg_num', 'schmoch35']].copy()\n",
    "# eneos_df = pd.merge(eneos_df, \n",
    "#                     schmoch_df.rename(columns={'Field_number':'schmoch35'})\\\n",
    "#                               .drop_duplicates(keep='first'), \n",
    "#                     on=['schmoch35'], \n",
    "#                     how='inner')\n",
    "# eneos_df[['ubiquity', 'Field_en', 'ki_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = pd.merge(c_df, schmoch_df, \n",
    "                    left_on=classification, right_on='Field_number', how='left')\\\n",
    "                    .drop(columns=['Field_number', classification])\\\n",
    "                    .rename(columns={'Field_en':classification})\n",
    "# graph_df = graph_df[graph_df['mcp']==1][[f'{ar}_{year_style}', region_corporation, 'ipc_class', 'mcp']]\n",
    "graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edge_df = graph_df[(graph_df[f'{ar}_{year_style}_period'] == f'{year_start}-{year_end}')&(graph_df['mcp'] == 1)].copy()\\\n",
    "                      [[region_corporation, classification, 'mcp']].rename(columns={'mcp':'Weight'})\n",
    "all_edge_df['Type'] = 'Undirected'\n",
    "all_edge_df\n",
    "\n",
    "all_node_list = list(all_edge_df[region_corporation].unique()) + list(all_edge_df[classification].unique())\n",
    "all_flag_list = [0] * len(all_edge_df[region_corporation].unique()) + [1] * len(all_edge_df[classification].unique())\n",
    "all_node_df = pd.DataFrame(all_node_list, columns=['label']).reset_index(drop=False).rename(columns={'index':'node_id'})\n",
    "all_node_df['projected'] = all_flag_list\n",
    "all_node_df['node_id'] += 1\n",
    "\n",
    "all_edge_df = pd.merge(all_edge_df, all_node_df, left_on=region_corporation, right_on='label', how='left').rename(columns={'node_id':'Source'})\n",
    "all_edge_df = pd.merge(all_edge_df, all_node_df, left_on=classification, right_on='label', how='left').rename(columns={'node_id':'Target'})\n",
    "\n",
    "all_edge_df = all_edge_df[['Source', 'Target', 'Type', 'Weight']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_node_df.to_csv(f'{output_dir}graph/{output_condition}_node.csv', \n",
    "                     encoding='utf-8', \n",
    "                     sep=',', \n",
    "                     index=False)\n",
    "all_edge_df.to_csv(f'{output_dir}graph/{output_condition}_edge.csv',\n",
    "                     encoding='utf-8',\n",
    "                     sep=',',\n",
    "                     index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_df.to_csv(f'{output_dir}graph/{output_condition}.csv', \n",
    "#                 encoding='utf-8', \n",
    "#                 sep=',', \n",
    "#                 index=False)\n",
    "# graph_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
